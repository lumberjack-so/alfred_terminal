# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

# File strategy s3/firebase
# fileStrategy: "s3"

# Custom interface configuration
interface:
  customWelcome: "Welcome to AlfredOS!"
  # MCP Servers UI configuration
  mcpServers:
    placeholder: 'Skills'
  # Privacy policy settings
  privacyPolicy:
    externalUrl: 'https://lumberjack.so/privacy-policy'
    openNewTab: true

  # Terms of service
  termsOfService:
    externalUrl: 'https://lumberjack.so/tos'
    openNewTab: true
    modalAcceptance: true
    modalTitle: "Terms of Service for AlfredOS"
    modalContent: |
      # Terms and Conditions for AlfredOS

      *Effective Date: December 1, 2024*

      Welcome to AlfredOS, the click-to-deploy business operating system for solopreneurs and indie teams, developed by Ugly Code LLC and available at https://lumberjack.so. These Terms of Service ("Terms") govern your use of AlfredOS and the services we offer. By accessing or using AlfredOS, you agree to be bound by these Terms and our Privacy Policy.

      ## 1. Open Source License

      AlfredOS is open-source software licensed under the MIT License. You are free to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software, subject to the conditions of the MIT License. The full license text is available in the project repository.

      ## 2. Service Usage

      AlfredOS is designed as a unified business OS that integrates various tools including n8n, Cal.com, Ghost, Supabase, and NocoDB through Model Context Protocol (MCP) connections. You agree to use these integrated services in compliance with their respective terms of service and in a lawful manner.

      ## 3. User Data and Privacy

      We collect minimal personal data necessary to provide and improve our services, as described in our Privacy Policy. When you deploy AlfredOS on Railway or other platforms, you maintain control over your data. We do not access your deployed instances unless explicitly authorized for support purposes.

      ## 4. Acceptable Use

      You agree to use AlfredOS only for lawful purposes and in a manner that does not infringe the rights of others. Prohibited uses include but are not limited to: illegal activities, harassment, distribution of malware, or any activity that disrupts or damages the service or its users.

      ## 5. Disclaimer of Warranties

      AlfredOS is provided "AS IS" without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose, and non-infringement. Ugly Code LLC makes no warranty that the service will be uninterrupted, secure, or error-free.

      ## 6. Limitation of Liability

      In no event shall Ugly Code LLC, its officers, directors, employees, or agents be liable for any indirect, incidental, special, consequential, or punitive damages arising out of or related to your use of AlfredOS.

      ## 7. Governing Law

      These Terms shall be governed by and construed in accordance with the laws of the State of California, United States, without giving effect to any principles of conflicts of law.

      ## 8. Changes to the Terms

      We reserve the right to modify these Terms at any time. Changes will be posted on our website, and your continued use of AlfredOS after such changes constitutes acceptance of the new Terms.

      ## 9. Contact Information

      If you have any questions about these Terms, please contact us at:
      
      Ugly Code LLC
      166 Geary St, STE1500 #631
      San Francisco, CA 94108, USA
      
      More information available at: https://lumberjack.so

      By using AlfredOS, you acknowledge that you have read these Terms of Service and agree to be bound by them.

  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  # Temporary chat retention period in hours (default: 720, min: 1, max: 8760)
  # temporaryChatRetention: 1

# Example Cloudflare turnstile (optional)
#turnstile:
#  siteKey: "your-site-key-here"
#  options:
#    language: "auto"    # "auto" or an ISO 639-1 language code (e.g. en)
#    size: "normal"      # Options: "normal", "compact", "flexible", or "invisible"

# Example Registration Object Structure (optional)
registration:
  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook', 'apple', 'saml']
  # allowedDomains:
  # - "gmail.com"


# Example Balance settings
# balance:
#   enabled: false
#   startBalance: 20000
#   autoRefillEnabled: false
#   refillIntervalValue: 30
#   refillIntervalUnit: 'days'
#   refillAmount: 10000

 speech:
  speechTab:
    conversationMode: true
    advancedMode: true
    speechToText:
      engineSTT: "external"
      languageSTT: "English (US)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true
   tts:
    openai:
       url: ''
       apiKey: '${OPENAI_API_KEY}'
       model: 'gpt-4o-mini-tts'
       voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer','ballad','verse','sage','coral']
    elevenlabs:
      apiKey: '${ELEVENLABS_API_KEY}'
      model: 'eleven_flash_v2_5'
      voices: ['c6SfcYrb2t09NHXiT80T', 'Fahco4VZzobUeiPqni1S', 'kdmDKE6EkgrWrrykO9Qt', 'Aa6nEBJJMKJwJkCx8VU2']   


   stt:
     openai:
       url: ''
       apiKey: '${OPENAI_API_KEY}'
       model: 'gpt-4o-mini-transcribe'

# rateLimits:
#   fileUploads:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for file uploads per user
#   conversationsImport:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user

# Example Actions Object Structure
actions:
  allowedDomains:
    - "swapi.dev"
    - "librechat.ai"
    - "google.com"

# Example MCP Servers Object Structure 
mcpServers:
  n8n:
      type: stdio
      command: "node"
      args: ["/opt/n8n-mcp/dist/mcp/index.js"]
      env:
        MCP_MODE: "stdio"
        LOG_LEVEL: "info"
        N8N_API_URL: "${N8N_URL}"
        N8N_API_KEY: "${N8N_API_KEY}"

  ghost:
    type: stdio
    command: "npx"
    args: ["-y", "@fanyangmeng/ghost-mcp"]
    env:
      GHOST_API_URL: "${GHOST_API_URL}"
      GHOST_ADMIN_API_KEY: "${GHOST_ADMIN_API_KEY}"
      GHOST_CONTENT_API_KEY: "${GHOST_CONTENT_API_KEY}"
      GHOST_API_VERSION: "v5.0"
  
  # Cal.com MCP Server
  calcom:
    type: streamable-http
    url: "https://server.smithery.ai/@mumunha/cal_dot_com_mcpserver/mcp"
    params:
      # Smithery authentication
      api_key: "${SMITHERY_API_KEY}"
      profile: "${SMITHERY_PROFILE}"
      # Cal.com service configuration
      calcomApiKey: "${CALCOM_API_KEY}"
    timeout: 30000
    initTimeout: 10000
  
  # Supabase MCP Server
  supabase:
    type: streamable-http
    url: "https://server.smithery.ai/@supabase-community/supabase-mcp/mcp"
    params:
      # Smithery authentication
      api_key: "${SMITHERY_API_KEY}"
      profile: "${SMITHERY_PROFILE}"
      # Supabase service configuration
      accessToken: "${SUPABASE_ACCESS_TOKEN}"
    timeout: 30000
    initTimeout: 10000
  
  # Optional: Puppeteer for browser automation
  # puppeteer:
  #   type: stdio
  #   command: npx
  #   args:
  #     - -y
  #     - "@modelcontextprotocol/server-puppeteer"
  #   timeout: 300000  # 5 minutes timeout for this server

# Definition of custom endpoints
endpoints:
  # assistants:
  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates
  #   timeoutMs: 180000  # Timeout for assistant operations
  #   # Should only be one or the other, either `supportedIds` or `excludedIds`
  #   supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
  #   # excludedIds: ["asst_excludedAssistantId"]
  #   # Only show assistants that the user created or that were created externally (e.g. in Assistants playground).
  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`
  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature
  #   retrievalModels: ["gpt-4-turbo-preview"]
  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["code_interpreter", "retrieval", "actions", "tools", "image_vision"]
  # agents:
  #   # (optional) Default recursion depth for agents, defaults to 25
  #   recursionLimit: 50
  #   # (optional) Max recursion depth for agents, defaults to 25
  #   maxRecursionLimit: 100
  #   # (optional) Disable the builder interface for agents
  #   disableBuilder: false
  #   # (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["execute_code", "file_search", "actions", "tools"]
  custom:
    # Groq Example
    # - name: 'groq'
    #   apiKey: '${GROQ_API_KEY}'
    #   baseURL: 'https://api.groq.com/openai/v1/'
    #   models:
    #     default:
    #       [
    #         'llama3-70b-8192',
    #         'llama3-8b-8192',
    #         'llama2-70b-4096',
    #         'mixtral-8x7b-32768',
    #         'gemma-7b-it',
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'mixtral-8x7b-32768'
    #   modelDisplayLabel: 'groq'

    # Mistral AI Example
    # - name: 'Mistral' # Unique name for the endpoint
    #   # For `apiKey` and `baseURL`, you can use environment variables that you define.
    #   # recommended environment variables:
    #   apiKey: '${MISTRAL_API_KEY}'
    #   baseURL: 'https://api.mistral.ai/v1'
    #
    #   # Models configuration
    #   models:
    #     # List of default models to use. At least one value is required.
    #     default: ['mistral-tiny', 'mistral-small', 'mistral-medium']
    #     # Fetch option: Set to true to fetch models from API.
    #     fetch: true # Defaults to false.
    #
    #   # Optional configurations
    #
    #   # Title Conversation setting
    #   titleConvo: true # Set to true to enable title conversation
    #
    #   # Title Method: Choose between "completion" or "functions".
    #   # titleMethod: "completion"  # Defaults to "completion" if omitted.
    #
    #   # Title Model: Specify the model to use for titles.
    #   titleModel: 'mistral-tiny' # Defaults to "gpt-3.5-turbo" if omitted.
    #
    #   # Summarize setting: Set to true to enable summarization.
    #   # summarize: false
    #
    #   # Summary Model: Specify the model to use if summarization is enabled.
    #   # summaryModel: "mistral-tiny"  # Defaults to "gpt-3.5-turbo" if omitted.
    #
    #   # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.
    #   # forcePrompt: false
    #
    #   # The label displayed for the AI model in messages.
    #   modelDisplayLabel: 'Mistral' # Default is "AI" when not set.
    #
    #   # Add additional parameters to the request. Default params will be overwritten.
    #   # addParams:
    #     # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/
    #
    #   # Drop Default params parameters from the request. See default params in guide linked below.
    #   # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
    #   dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']

    # OpenRouter Example
    - name: 'OpenRouter'
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      apiKey: '${OPENROUTER_KEY}'
      baseURL: 'https://openrouter.ai/api/v1'
      models:
        default: ['meta-llama/llama-3-70b-instruct']
        fetch: true
      titleConvo: true
      titleModel: 'meta-llama/llama-3-70b-instruct'
      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.
      dropParams: ['stop']
      modelDisplayLabel: 'OpenRouter'

    # Portkey AI Example
    # - name: "Portkey"
    #   apiKey: "dummy"
    #   baseURL: 'https://api.portkey.ai/v1'
    #   headers:
    #     x-portkey-api-key: '${PORTKEY_API_KEY}'
    #     x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'
    #   models:
    #     default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']
    #     fetch: true
    #   titleConvo: true
    #   titleModel: 'current_model'
    #   summarize: false
    #   summaryModel: 'current_model'
    #   forcePrompt: false
    #   modelDisplayLabel: 'Portkey'
    #   iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf
# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5
#       fileSizeLimit: 10  # Maximum size for an individual file in MB
#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true  # Disables file uploading to the OpenAI endpoint
#     default:
#       totalSizeLimit: 20
#     YourCustomEndpointName:
#       fileLimit: 2
#       fileSizeLimit: 5
#   serverFileSizeLimit: 100  # Global server file size limit in MB
#   avatarSizeLimit: 2  # Limit for user avatar image size in MB
#   imageGeneration: # Image Gen settings, either percentage or px
#     percentage: 100
#     px: 1024
#   # Client-side image resizing to prevent upload errors
#   clientImageResize:
#     enabled: false  # Enable/disable client-side image resizing (default: false)
#     maxWidth: 1900  # Maximum width for resized images (default: 1900)
#     maxHeight: 1900  # Maximum height for resized images (default: 1900)
#     quality: 0.92  # JPEG quality for compression (0.0-1.0, default: 0.92)
# # See the Custom Configuration Guide for more information on Assistants Config:
# # https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint

# Memory configuration for user memories
# memory:
#   # (optional) Disable memory functionality
#   disabled: false
#   # (optional) Restrict memory keys to specific values to limit memory storage and improve consistency
#   validKeys: ["preferences", "work_info", "personal_info", "skills", "interests", "context"]
#   # (optional) Maximum token limit for memory storage (not yet implemented for token counting)
#   tokenLimit: 10000
#   # (optional) Enable personalization features (defaults to true if memory is configured)
#   # When false, users will not see the Personalization tab in settings
#   personalize: true
#   # Memory agent configuration - either use an existing agent by ID or define inline
#   agent:
#     # Option 1: Use existing agent by ID
#     id: "your-memory-agent-id"
#     # Option 2: Define agent inline
#     # provider: "openai"
#     # model: "gpt-4o-mini"
#     # instructions: "You are a memory management assistant. Store and manage user information accurately."
#     # model_parameters:
#     #   temperature: 0.1
